import matplotlib.pyplot as plt
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping

def main():
    num_classes = 10

    # Input image dimensions
    img_rows, img_cols = 28, 28

    # The data, split between train and test sets
    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

    # Reshape and normalize the data
    x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols).astype('float32')
    x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols).astype('float32')

    # Normalize the pixel values to range [0, 1]
    x_train /= 255.0
    x_test /= 255.0

    # One-hot encode the labels
    y_train = to_categorical(y_train, num_classes)
    y_test = to_categorical(y_test, num_classes)

    # Build the Neural Network model (MLP)
    model = Sequential()

    # Input layer and first fully connected layer (Dense layer)
    model.add(Dense(128, activation='relu', input_dim=img_rows * img_cols))

    # Dropout layer to reduce overfitting
    model.add(Dropout(0.2))

    # Second fully connected layer
    model.add(Dense(64, activation='relu'))

    # Output layer with 10 classes (fashion categories)
    model.add(Dense(num_classes, activation='softmax'))

    model.summary()

    batch_size = 128
    epochs = 50

    # Compile the model
    model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

    # Early stopping callback
    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

    # Train the model and store the history
    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[early_stopping])

    # Evaluate the model
    score = model.evaluate(x_test, y_test, verbose=0)
    print("Test loss:", score[0])
    print("Test accuracy:", score[1])

    # Save the model (optional)
    # model.save('fashion_mnist_mlp_model.h5')

    # Plot training & validation loss values
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Train', color='red', linewidth=2)
    plt.plot(history.history['val_loss'], label='Validation', color='blue', linewidth=2)
    plt.title('Training and Validation Loss', fontname='serif', fontsize=14)
    plt.xlabel('Epochs', fontname='serif', fontsize=12)
    plt.ylabel('Loss', fontname='serif', fontsize=12)
    plt.legend()
    plt.grid(True)
    plt.savefig('fashion_loss_plot_mlp.png', dpi=300)
    plt.show()

    # Plot training & validation accuracy values
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['accuracy'], label='Train', color='red', linewidth=2)
    plt.plot(history.history['val_accuracy'], label='Validation', color='blue', linewidth=2)
    plt.title('Training and Validation Accuracy', fontname='serif', fontsize=14)
    plt.xlabel('Epochs', fontname='serif', fontsize=12)
    plt.ylabel('Accuracy', fontname='serif', fontsize=12)
    plt.legend()
    plt.grid(True)
    plt.savefig('fashion_accuracy_plot_mlp.png', dpi=300)
    plt.show()


    main()
