import numpy as np

def sigmoid(z):
    return 1 / (1 + np.exp(-z))


def compute_cost(X, y, beta, lambd):
    m = len(y)
    h = sigmoid(np.dot(X, beta))
    cost = (-1/m) * (np.dot(y, np.log(h)) + np.dot((1 - y), np.log(1 - h)))
    reg_term = (lambd/(2*m)) * np.sum(beta[1:]**2)  
    return cost + reg_term

# Gradient descent with L2 regularization
def gradient_descent(X, y, beta, alpha, lambd, num_iterations):
    m = len(y)
    cost_history = []
    
    for i in range(num_iterations):
        h = sigmoid(np.dot(X, beta))
        gradient = (1/m) * np.dot(X.T, (h - y)) + (lambd/m) * np.append(0, beta[1:])  # Regularization on beta_1 to beta_n
        beta -= alpha * gradient
        cost = compute_cost(X, y, beta, lambd)
        cost_history.append(cost)
    
    return beta, cost_history


grain_size = np.array([0.245, 0.247, 0.285, 0.299, 0.327, 0.347, 0.356, 0.36, 0.363, 0.364, 0.398, 0.4, 0.409, 0.421,
                       0.432, 0.473, 0.509, 0.529, 0.561, 0.569, 0.594, 0.638, 0.656, 0.816, 0.853, 0.938, 1.036, 1.045])
spiders = np.array([0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])


X = np.c_[np.ones(grain_size.shape[0]), grain_size, grain_size**2, 1/(grain_size - 0.41) ,1/grain_size**2]
y = spiders

beta = np.zeros(X.shape[1])  
alpha = 1e-3 
lambd = 50  
num_iterations = 50000

beta_optimal, cost_history = gradient_descent(X, y, beta, alpha, lambd, num_iterations)

print("Optimal beta values: ", beta_optimal)

cost_history = np.array(cost_history).flatten()

plt.figure(figsize=(8, 6))
plt.plot(range(len(cost_history)), cost_history, color='blue')
plt.xlabel('Epoch')
plt.ylabel('Cost function')
plt.grid(True)
plt.show()

binary_predictions = predict(X, beta_optimal)
plt.figure(figsize=(8, 6))
plt.scatter(grain_size, spiders, color='blue', label=' Data')
plt.scatter(grain_size, binary_predictions, color='red', marker='x', label='Predicted data')
plt.xlabel('Grain Size (mm)')
plt.ylabel('Spider Presence')
plt.legend()
plt.grid(True)
plt.show()


accuracy = np.mean(binary_predictions == y.flatten()) * 100
print(f"Training Accuracy: {accuracy:.2f}%")
